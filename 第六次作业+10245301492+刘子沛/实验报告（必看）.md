## 实验六：深度学习与聚类算法

#### 11. 在上一节课作业的基础上，请利用深度学习方法，对各学科做一个排名模型，能够较好的预测出排名位置，并且利用MSE，MAPE等指标来进行评价模型的优劣

在上一节课的作业中，我发现原数据的第一行和最后一行有冗余信息，可能会干扰表格的读取

第一行是表头，应该去掉：

![](.\pictures\1.png)

最后一行是 Copyright ?2025 Clarivate，也应该去掉：

![](.\pictures\3.png)

在 Powershell 执行下面命令：

```powershell
$src="D:\ESI\download"; $dst="D:\ESI\clean"; New-Item -ItemType Directory -Force -Path $dst | Out-Null
Get-ChildItem $src -Filter *.csv | ForEach-Object {
  $lines = Get-Content $_.FullNameGet-ChildItem $src -Filter *.csv
  $lines[1..($lines.Count-2)] | Set-Content -Encoding UTF8 (Join-Path $dst $_.Name)
}
```

解释一下：

1. src 是原始文件路径，dst 是目标文件路径
2. New-Item 用于创建一个新目录，如果 D:\ESI\clean 不存在，会自动创建
3. Get-ChildItem $src -Filter *.csv 会列出 src 中所有扩展名为 .csv 的文件
4. ForEach-Object 遍历每个文件
5. \$lines = Get-Content $_.FullName 会把整个文件的内容读成一个字符串数组，每一行是一个元素
6. \$lines[1..($lines.Count-2)] 是数组切片语法，表示从第二行到倒数第二行，删除文件的第一行和最后一行
7. Set-Content 把上一步得到的“去掉第一行的内容”写入到新的文件中

可以看到，第一行已经成功去掉了：

![](.\pictures\2.png)

最后一行也成功去掉了：

![](.\pictures\4.png)

我整理了一下邱学长提到的深度学习步骤：

> 定义数据集
> 定义模型
> 定义训练过程
> 训练多少轮次
> 参数冻结
> 在测试集上跑一遍
> 深层次MMP，每层加一些归一化、正则化、非线性组合

首先，题目要求我们对各学科做一个排名模型，预测排名位置

电脑通过学习一些国家的（Web of Science Documents，Cites，Cites/Paper，Cites/Paper，排名），

再给其他国家的（Web of Science Documents，Cites，Cites/Paper，Cites/Paper），可以推测出排名

我们来明确一下输入和输出：

​	输入：多个 CSV，每个 CSV 代表一个学科，第一列就是排名，这是通过人工观察发现的

​	输出：对于每个学科，在**测试值**上跑预测模型，得出的**真实值**对比**预测值**的表，以及各项指标的总表

我们要明确一点，每个学科的排名预测模型都应该是**独立**的

因此，要循环遍历每个csv文件，**写一个循环**

在循环中，依次遍历存放多个 CSV 文件路径的列表，并同时获取每个文件的编号（从 1 开始）和路径

```python
for i, csv_path in enumerate(csvs, 1):
```
然后，取出当前表格最左侧的第一列列名，并打印当前处理进度，包括文件编号、总文件数、学科文件名以及该排名列的列名，用来提示程序正在处理哪个学科的排名数据

```python
label_col = df.columns[0]
print(f"\n=== [{i}/{len(csvs)}] 学科: {csv_path.name} | 排名列: {label_col} ===")
```

前面提到过了，我们通过一个学校的：

​     X =（Web of Science Documents，Cites，Cites/Paper，Cites/Paper）

来预测它的排名，设为 Y

将表格中最左侧的排名列转成数值型，然后把剩下的所有列作为特征矩阵 X，并通过 to_numeric_df() 函数将这些特征列全部转换为数值类型，以便后续模型训练或聚类分析使用

```python
y_raw = pd.to_numeric(df[label_col], errors="coerce").astype(float)
X = df.drop(columns=[label_col])
X = to_numeric_df(X)
```

不要忘了过滤掉在排名列中存在缺失值的行，只保留排名有效的样本，使得 X 和 Y 严格对应且都是完整的数值型数据，从而确保后续训练或聚类过程不会受到缺失数据干扰

```python
mask = y_raw.notna()
X = X.loc[mask].copy()
y_raw = y_raw.loc[mask].astype(float)
```
然后，划分数据集

课堂上，老师讲解了测试集、验证集、测试集

邱学长也提到了合适的比例：60%，20%，20%

我们还要计算当前样本总数 N，并生成一个从 0 到 N-1 的索引数组 idx_all，然后调用 split_60_20_20_idx() 函数，基于给定随机种子 SEED 进行数据集的划分

```python
N = len(row_ids)
idx_all = np.arange(N)
idx_tr, idx_va, idx_te = split_60_20_20_idx(idx_all, seed=SEED)
```
然后，我们要 scale 一下特征，因为特征的大小范围很不统一

创建一个标准化器 StandardScaler()，以训练集数据为基准进行特征标准化处理——即让每个特征的均值为 0、标准差为 1

```python
scaler = StandardScaler()
X_train = scaler.fit_transform(X_np[idx_tr])
X_val   = scaler.transform(X_np[idx_va])
X_test  = scaler.transform(X_np[idx_te])
```

排名也要 scale 一下

经过下面的处理后，模型预测输出也是 [0,1] 之间的小数，更易收敛、数值稳定，并可在评估阶段反归一化回真实排名

```python
y_min = float(np.min(y_np))
y_max_v = float(np.max(y_np))
y_max = y_max_v if y_max_v != y_min else (y_min + 1.0)
def norm(y): return (y - y_min) / (y_max - y_min)

y_train = norm(y_np[idx_tr])
y_val   = norm(y_np[idx_va])
y_test  = norm(y_np[idx_te])
```
然后，调用自定义函数 train_one() 来训练一个深度学习模型，并返回在测试集上的预测结果

```python
_, predict_rank = train_one(
    X_train, y_train, X_val, y_val, X_test, y_test,
    y_min=y_min, y_max=y_max, device=device
)
```
先插叙一下，深度学习模型的**内部**是怎么工作的？

首先，动态选择合适的归一化方式，构建深度学习模型，并定义一个稳健的损失函数

```python
norm_kind = "batch" if len(X_train) >= 2 else "layer"
model = DeepRankMLP(X_train.shape[1], norm_kind=norm_kind).to(device)
huber = nn.SmoothL1Loss(beta=1.0)  # robust to outliers
```

训练分为两个阶段，full training 和 freeze and fine-tune

**1. full training**

先用 AdamW 优化器，并配上 StepLR 学习率调度器（每 40 个 epoch 将学习率乘以 0.5），随后把训练集与验证集的 NumPy 特征/标签  转成 PyTorch 张量 并封装为 TensorDataset，为后续用 DataLoader 批量迭代训练与评估做准备

```python
opt = torch.optim.AdamW(model.parameters(), lr=LR1, weight_decay=WEIGHT_DECAY) sched = torch.optim.lr_scheduler.StepLR(opt, step_size=40, gamma=0.5) tr_ds = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train_norm).float()) va_ds = TensorDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val_norm).float())
```
构建 PyTorch 的 DataLoader，也就是让模型能够按批次取出训练数据和验证数据的关键部分

```python
bs_eff = min(BATCH_SIZE, len(tr_ds))
drop_last = (len(tr_ds) >= 2)
tr_dl = DataLoader(tr_ds, batch_size=bs_eff, shuffle=True, drop_last=drop_last)
va_dl = DataLoader(va_ds, batch_size=min(BATCH_SIZE, len(va_ds)), shuffle=False)
```

把模型输出的归一化预测结果（0~1之间）反变换回原始排名范围

因为我们前面把排名 scale 到了 0~1之间，可是题目想要的肯定是预测原始排名

```python
def denorm(y_hat_norm: np.ndarray) -> np.ndarray:
    return y_min + np.clip(y_hat_norm, 0.0, 1.0) * (y_max - y_min)
```

下面实现一个完整的训练轮次循环

每轮训练都会遍历整个训练集，将模型设为训练模式，再逐批取出数据送入网络进行前向传播，计算预测值与真实值的 Huber 损失

接着清空梯度、反向传播、裁剪梯度防止爆炸，最后用 AdamW 优化器更新参数

每个 epoch 结束后，学习率调度器按计划降低学习率，以帮助模型在后期更平稳地收敛

```python
nonlocal best_state, best_val_mse_rank
for ep in range(1, epochs + 1):
    if len(tr_dl) == 0:
        break
    model.train()
    for xb, yb in tr_dl:
        xb, yb = xb.to(device), yb.to(device)
        pred = model(xb)
        loss = huber(pred, yb)
        opt.zero_grad()
        loss.backward()
        nn.utils.clip_grad_norm_(model.parameters(), 5.0)
        opt.step()
    sched.step()
```

先切换到 eval 模式并关闭梯度计算，然后用验证集逐批预测，得到所有预测值和真实值

接着将它们反归一化为原始排名，用 MSE 计算误差

若当前误差小于历史最优值，就更新 best_val_mse_rank 并保存当前模型参数

```python
model.eval()
with torch.no_grad():
    yp, yt = [], []
    for xb, yb in va_dl:
        xb = xb.to(device)
        yp.append(model(xb).cpu().numpy())
        yt.append(yb.cpu().numpy())
    if len(yp) == 0:
        continue
    y_pred_norm = np.concatenate(yp).reshape(-1)
    y_true_norm = np.concatenate(yt).reshape(-1)
    y_pred_rank = denorm(y_pred_norm)
    y_true_rank = denorm(y_true_norm)
    v_mse_rank = mse_np(y_true_rank, y_pred_rank)
    if v_mse_rank < best_val_mse_rank:
        best_val_mse_rank = v_mse_rank
        best_state = {k: v.clone() for k, v in model.state_dict().items()}
```
**2. freeze and fine-tune**

接下来是第二部分，冻结参数训练

首先调用冻结模型前半部分的参数，只让后半部分参与训练

接着，用 AdamW 优化器重新初始化，只更新未冻结部分的参数，并设置一个更小的学习率 LR2 与相同的 weight_decay 来避免过拟合

然后建立新的 StepLR 调度器，每 20 轮将学习率减半

最后调用 run_epochs(EPOCHS_2) 进行多轮训练

```python
freeze_first_half(model, True)
opt = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR2, weight_decay=WEIGHT_DECAY)
sched = torch.optim.lr_scheduler.StepLR(opt, step_size=20, gamma=0.5)
run_epochs(EPOCHS_2)
```

最后是预测排名阶段

首先，将模型切换到评估模式，关闭 dropout 和 batch norm 的随机行为

关闭梯度计算，避免浪费显存和计算资源

把输入的 NumPy 数组 X_np 转换为 PyTorch 张量并移动到设备上

调用模型获得预测的归一化输出 yhat_norm，再转回 NumPy 格式

通过 denorm() 函数反归一化，将结果映射回真实的排名区间

```python
def predict_rank(X_np: np.ndarray) -> np.ndarray:
    model.eval()
    with torch.no_grad():
        X_t = torch.from_numpy(X_np).float().to(device)
        yhat_norm = model(X_t).cpu().numpy().reshape(-1)
    return denorm(yhat_norm)
```

最后，利用训练好的模型在测试集上进行预测，并计算预测结果与真实排名之间的多种评估指标，用于衡量模型性能

```python
y_pred_te = predict_rank(X_test)
y_true_te = y_np[idx_te]

metrics = compute_metrics(y_true_te, y_pred_te)
```

关于输出部分，我们前面提到过了：

对于每个学科，在**测试值**上跑预测模型，得出的**真实值**对比**预测值**的表，以及各项指标的总表

首先是各项指标的输出，需要的数据都在metrics字典中

依次输出即可

```python
print("[测试] " + "  ".join([
    f"MSE={metrics['MSE']:.4f}",
    f"RMSE={metrics['RMSE']:.2f}",
    f"MAE={metrics['MAE']:.2f}",
    f"MAPE={metrics['MAPE']:.2f}%",
    f"MedAE={metrics['MedianAE']:.2f}",
    f"R2={metrics['R2']:.3f}",
    f"nRMSE={metrics['nRMSE']:.3f}",
    f"Spearman={metrics['Spearman']:.3f}",
    f"Kendall={metrics['Kendall']:.3f}",
]))
```
然后是对比表

把模型在测试集上某所大学的真实排名和预测排名保存为一个独立的结果表

```python
pred_df = pd.DataFrame({
    "row_id": row_ids[idx_te],
    "true_rank": y_true_te,
    "pred_rank": y_pred_te,
})
```
生成每个学科预测结果的 CSV 文件名并保存预测结果表格

```python
stem = csv_path.stem
safe = "".join([ch if ch.isalnum() or ch in ("-","_") else "_" for ch in stem])
pred_path = (Path(__file__).resolve().parent / f"predictions_{safe}.csv")
pred_df.to_csv(pred_path, index=False)
print(f"已保存测试对比表: {pred_path.resolve()}")
```

但是我想把所有学科的各项指标汇总到一张表中，以便**纵向对比**

把每个学科对应的模型评估指标保存到一个总表列表中，以便最后统一生成总表

```python
row = {"subject_csv": csv_path.name}
row.update(metrics)
rows.append(row)
```
最后，在所有学科模型的预测模型评测结果汇总后，生成一个综合评价表 deep_learning.csv，并按 MSE 升序排序显示和保存


```python
if rows:
    out = pd.DataFrame(rows).sort_values("MSE")
    out_path = (Path(__file__).resolve().parent / "deep_learning.csv")
    out.to_csv(out_path, index=False)
    print("\n=== 总结（按 MSE 升序） ===")
    print(out.to_string(index=False))
    print(f"\n结果已保存到: {out_path.resolve()}")
```

以上的完整代码，请查看 deep_learning.py

各学科排名模型在**测试集**上的预测值与真实值对比表格，都在附件中：

![](.\pictures\6.png)

我这里随机选一个学科展示一下：

![](.\pictures\7.png)

可以看到，预测值与真实值还是比较接近的，说明模型预测效果好

预测的排名值是一个小数，而不是整数，虽然排名只能是整数

如果需要整数，把预测的排名值四舍五入即可，或者向偶数取整

不过我觉得小数也是有意义的，因为它本身只是一个估计

比如一个大学预测排名为 2.5，那可以认为它的排名大概是第二、第三

各学科排名模型在**测试集**上的**各项指标**如下：

![](.\pictures\5.png)

其中的 nRMSE 是 RMSE 按数值范围归一化之后的，很有参考价值：

​	nRMSE < 0.10：很好

​	0.10–0.20：可用

而各学科排名模型在**测试集**上的 nRMSE 都小于 0.10，说明模型预测效果**很好**

各项指标的总表也在附件中，叫 deep_learning.csv

#### 12. 对ESI的数据进行聚类，发现与华师大类似的学校有哪些，并分析下原因

数据是每个学科一个表格，适合观察某个学科哪些高校厉害

但是如果想将全球高校聚类，应该观察**同一个高校的不同学科**，数据的组织形式是不适合这种观察的

我的思路是把所有表格合并成一个二维表格，每一行表示一个高校，每一列表示一个学科

某行某列的元素代表**某个高校在某个学科的排名**

手动构建这个二维表格的工作量是巨大的，我们肯定要写一个python程序

下面来构建二维表格，重复一下我的思路：

​	把所有表格合并成一个二维表格，每一行表示一个高校，每一列表示一个学科
​	
​	某行某列的元素代表**某个高校在某个学科的排名**

我们读取clean目录下的所有CSV文件，把二维表格输出到一个CSV文件中：

```python
INPUT_DIR = (Path(__file__).resolve().parent / "clean")
OUTPUT_CSV = (Path(__file__).resolve().parent / "build.csv")
```

先写一个函数，列出所有CSV文件：

```python
def list_subject_files(root: Path) -> list[Path]:
    files = sorted(root.glob("*.csv"))
    if not files:
        raise FileNotFoundError(f"No CSV files found in {root}")
    return files
```

对于每个学科表，我们只关心大学名称、学科名称、学科排名这三个信息

学科排名：rank 取文件的第一列（清洗后的名次列）

大学名称：university 取 'Institutions'

学科名称：subject 用文件名（去掉扩展名）

对于每个学科表，处理后返回一个 pd.DataFrame，包含三列：['university', 'subject', 'rank']

读入 CSV，找到表示名次的第一列，指定表示学校名称的 Institutions 列：

```python
df = pd.read_csv(csv_path, dtype=str)
rank_col = df.columns[0]
inst_col = "Institutions"

out = pd.DataFrame({
    "university": df[inst_col].astype(str).str.strip(),
    "rank": pd.to_numeric(df[rank_col], errors="coerce"),
}).dropna(subset=["university", "rank"])

out["rank"] = out["rank"].astype(int)
out["subject"] = csv_path.stem.strip()
return out[["university", "subject", "rank"]]
```

每个学科都会返回一个 pd.DataFrame，将所有 pd.DataFrame 合并：

```python
frames = [read_subject(p) for p in list_subject_files(input_dir)]
long_df = pd.concat(frames, ignore_index=True)
```

最后，按行、列排序：

```python
return pivot.sort_index().sort_index(axis=1)
```

以上预处理的完整代码请老师阅读 build.py

运行后，得到二维表格，取名叫 build.csv，同样在附件中：

![](.\pictures\8.png)

空白元素是正常的，代表这个高校在这个学科排名中**没有上榜**

有了这个表格，我们就可以直观地将全球高校进行分类

python 库中，sklearn 是非常好用的

它里面有一个 KMeans 模组，可以很方便地实现 KMeans 算法

首先，读取二维表格

第一列是学校名，单独存到 universities 中

其余列为各学科排名，存到一个矩阵中

某些学校在某些学科没有上榜，那么这一项就是空白的，怎么办？

我的创意是，填充这个学科最大排名的 2 倍，这样能体现该校这个学科的实力比较弱

```python
path = "build.csv"
df = pd.read_csv(path)
universities = df.iloc[:, 0]
X = df.iloc[:, 1:].fillna(df.max() * 2)
```
然后对各个学科排名数据进行标准化，都转化为 均值为 0、标准差为 1 的分布

```python
X_scaled = StandardScaler().fit_transform(X)
```

下面是整个聚类分析的核心步骤

先创建一个 KMeans 聚类器，n_clusters=8 表示希望将所有高校分成 8个聚类

random_state=42，固定随机数种子，保证每次运行结果一致

n_init=10 表示算法会尝试 10 次不同的随机初始中心，选择其中效果最好的一次作为最终模型，从而提高聚类稳定性

再将聚类标签作为新的一列 "Cluster" 添加到原始 DataFrame

```python
kmeans = KMeans(n_clusters=8, random_state=42, n_init=10)
labels = kmeans.fit_predict(X_scaled)
df["Cluster"] = labels
```
然后，我们来发现与华师大归到了同一个类别的学校有哪些

首先，找到 EAST CHINA NORMAL UNIVERSITY 所在的那一行

提取那一行的 Cluster 值，也就是华师大被归到的类别

然后，获取所有学校的名字构成的列表，也就是总表的第一列

在表格中查找 Cluster 值等于华师大的 Cluster 值，有哪些行

把这些行中的学校名称记录到一个列表中

最后输出出来

以上的完整代码，请查看 similar.py

```python
target = "EAST CHINA NORMAL UNIVERSITY"
if target in universities.values:
    target_cluster = df.loc[universities == target, "Cluster"].values[0]
    name_col = df.columns[0]
    similar_schools = df[df["Cluster"] == target][name_col].values
    print(f"与 {target} 聚类相似的高校：")
    print(similar_schools)
```

![](.\pictures\10.png)

不过归到华师大这一类的学校有很多，不知道哪几个最相似

我有两个思路：

1. 计算相似度，按照相似度从大到小排序，输出出来


```python
target_vec = X_scaled[universities.str.upper() == target.upper()][0].reshape(1, -1)
similarity = cosine_similarity(target_vec, X_scaled)[0]
df["Similarity"] = similarity

print("\n最相似的高校（按相似度降序）：")
print(df.sort_values("Similarity", ascending=False).head(50)[[name_col, "Similarity"]])
```

运行结果如下，输出了与华师大相似度前30名的高校，以及相似度

![](.\pictures\9.png)

2. 让聚类算法分的更细一些

   第一种方法其实也挺好的，但是题目毕竟要求使用**聚类算法**

   我还是觉得应该**把切题放到首位**

   在前面我提到过，n_clusters=8 表示希望将所有高校分成 8个聚类

   如果人工调一下这个参数，比如 令n_clusters=100

   那所有高校就会被分成100个聚类，每个聚类的高校数量也会变少
   
   这样改动：

```python
kmeans = KMeans(n_clusters=100, random_state=42, n_init=10)
labels = kmeans.fit_predict(X_scaled)
df["Cluster"] = labels
```

改动代码后，KMeans 聚类算法的运行结果如下：

![](.\pictures\11.png)

在实验报告的最后，我来分析一下这些高校与华师大相似的**原因**：

1. 师范类 / 教育与基础科学强校

   代表高校：北京师范大学、香港教育类大学

   这些学校在教育学、心理学、数学、环境科学等人文理交叉学科上布局与华师大非常接近；都是“教育+理科+环境+计算机”结构。

2. 理工与信息科学综合型大学

   代表高校：华南理工、电子科技大学、香港科技大学、挪威科技大学

   华师大近年理工科（尤其是计算机、信息科学、环境科学）发展迅猛，与这些“中等规模理工型大学”结构接近。

3. 工科强校但文理基础扎实

   代表高校：卡内基梅隆大学、德尔夫特理工大学、昆士兰科技大学

   这些大学在信息科学、人工智能、计算机、地球环境等领域的科研产出与华师大相似，尤其是AI与地球科学交叉研究。

4. 综合性大学

   代表高校：南加州大学体系、南卡罗来纳大学、马卡奥大学、格拉纳达大学、巴斯大学

   它们的科研特征是“多学科中等水平、部分学科突出”，整体分布平衡，与华师大ESI曲线（无极端强势学科，但全面均衡）接近。

5. 技术应用型大学

   代表高校：香港理工大学、香港城市大学、佛罗里达州立大学

   注重工程、社会科学与教育、环境等跨领域融合，这正是华师大在“双一流”中努力拓展的方向。
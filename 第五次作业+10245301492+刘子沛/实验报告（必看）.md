## 实验五：探索性分析与数据建模

#### 8. 请结合这些学科排名数据，分析全球高校可以大致分为哪几类?并且分析出与华师大类似的高校?

数据是每个学科一个表格，适合观察某个学科哪些高校厉害

但是如果想将全球高校分类，应该观察**同一个高校的不同学科**，数据的组织形式是不适合这种观察的

我的思路是把所有表格合并成一个二维表格，每一行表示一个高校，每一列表示一个学科

某行某列的元素代表**某个高校在某个学科的排名**

手动构建这个二维表格的工作量是巨大的，我们肯定要写一个python程序

但是原数据的表格第一行和最后一行应该先清理掉，以便python程序处理

这一步很重要，第8题和第10题都会用到

先打开一个csv看一下，发现第1行是说明文字**，**第2行才是表头：

![](.\pictures\1.png)

最后一行是 Copyright ?2025 Clarivate，也应该去掉：

![](.\pictures\3.png)

所以我们先把每个 CSV 的**第一行和最后一行删掉**，再导入

在 Powershell 执行下面命令：

```powershell
$src="D:\ESI\download"; $dst="D:\ESI\clean"; New-Item -ItemType Directory -Force -Path $dst | Out-Null
Get-ChildItem $src -Filter *.csv | ForEach-Object {
  $lines = Get-Content $_.FullNameGet-ChildItem $src -Filter *.csv
  $lines[1..($lines.Count-2)] | Set-Content -Encoding UTF8 (Join-Path $dst $_.Name)
}
```

解释一下：

1. src 是原始文件路径，dst 是目标文件路径
2. New-Item 用于创建一个新目录，如果 D:\ESI\clean 不存在，会自动创建
3. Get-ChildItem $src -Filter *.csv 会列出 src 中所有扩展名为 .csv 的文件
4. ForEach-Object 遍历每个文件
5. \$lines = Get-Content $_.FullName 会把整个文件的内容读成一个字符串数组，每一行是一个元素
6. \$lines[1..($lines.Count-2)] 是数组切片语法，表示从第二行到倒数第二行，删除文件的第一行和最后一行
7. Set-Content 把上一步得到的“去掉第一行的内容”写入到新的文件中

可以看到，第一行已经成功去掉了：

![](.\pictures\2.png)

最后一行也成功去掉了：

![](.\pictures\4.png)

下面来构建二维表格，重复一下我的思路：

​	把所有表格合并成一个二维表格，每一行表示一个高校，每一列表示一个学科

​	某行某列的元素代表**某个高校在某个学科的排名**

我们读取clean目录下的所有CSV文件，把二维表格输出到一个CSV文件中：

```python
INPUT_DIR = (Path(__file__).resolve().parent / "clean")
OUTPUT_CSV = (Path(__file__).resolve().parent / "8_build.csv")
```

先写一个函数，列出所有CSV文件：

```python
def list_subject_files(root: Path) -> list[Path]:
    files = sorted(root.glob("*.csv"))
    if not files:
        raise FileNotFoundError(f"No CSV files found in {root}")
    return files
```

对于每个学科表，我们只关心大学名称、学科名称、学科排名这三个信息

学科排名：rank 取文件的第一列（清洗后的名次列）

大学名称：university 取 'Institutions'

学科名称：subject 用文件名（去掉扩展名）

对于每个学科表，处理后返回一个 pd.DataFrame，包含三列：['university', 'subject', 'rank']

读入 CSV，找到表示名次的第一列，指定表示学校名称的 Institutions 列：

```python
df = pd.read_csv(csv_path, dtype=str)
rank_col = df.columns[0]
inst_col = "Institutions"

out = pd.DataFrame({
    "university": df[inst_col].astype(str).str.strip(),
    "rank": pd.to_numeric(df[rank_col], errors="coerce"),
}).dropna(subset=["university", "rank"])

out["rank"] = out["rank"].astype(int)
out["subject"] = csv_path.stem.strip()
return out[["university", "subject", "rank"]]
```

每个学科都会返回一个 pd.DataFrame，将所有 pd.DataFrame 合并：

```python
frames = [read_subject(p) for p in list_subject_files(input_dir)]
long_df = pd.concat(frames, ignore_index=True)
```

最后，按行、列排序：

```python
return pivot.sort_index().sort_index(axis=1)
```

以上预处理的完整代码请老师阅读 8_build.py

运行后，得到二维表格，取名叫 8_build.csv，同样在附件中：

![](.\pictures\5.png)

空白元素是正常的，代表这个高校在这个学科排名中**没有上榜**

有了这个表格，我们就可以直观地将全球高校进行分类

全球高校可以大致分为哪几类？

​	综合类、理工类、医学类、文科-社科类

​	这还不够，为了严格地将所有高校分类，我需要通过观察表格数据，设计一个**判定标准**

**综合类**：至少两大组各有 ≥2 门学科进入 Top200，且总覆盖 ≥10 门

**理工类**：理工组 Top100 学科数 ≥2，且明显多于其他两组（约 ≥2 倍），生命/社科 Top100 极少（≤1）

**医学类**：生命-医学组 Top100 学科数 ≥2，且明显多于其他两组（约 ≥2 倍）

**文科-社科类**：社科组有 Top200 学科 ≥1，且理工/生命医学 Top100 皆为 0

**未分类**：其余的

我将每个类别的所有高校整理成了表格，在附件中供老师查看：

![](.\pictures\6.png)

哪些高校与华师大类似?

按照刚才的分类标准，华师大属于“未分类”的高校，所以无法直接找到同类

![](.\pictures\7.png)

现在的问题是，如果给定两个大学的各学科排名向量，如何计算相似度？

首先，排名应该转化为**得分**，因为名次越小越强，而余弦相似度默认“数值越大越强”：

得分介于0到1，排名越大，得分越小

![](.\pictures\8.png)

未上榜怎么处理？不是 0 分，而是设成“比榜尾还低一点”的极低分：

![](.\pictures\9.png)

这样，处理后的两个高校的向量就可以计算相似度了，只需要计算**余弦相似度**

首先，我们需要从 8_build.csv 文件中加载数据，并且将名次列从字符串转换为数值类型：

```python
df = pd.read_csv(CSV)
u, subs = df.columns[0], df.columns[1:]
df[subs] = df[subs].apply(pd.to_numeric, errors="coerce")
```

接下来，我们将每个学科的排名转换为得分：

```python
m = df[subs].max(skipna=True)             # 各学科最大名次 max_rank_s
den = (m - 1).replace(0, np.nan)          # 防止除零
score = 1 - (df[subs] - 1).div(den, axis=1) # 式(1)
score = score.clip(0, 1).fillna(1 / (m + 1)) # 未上榜用极低分
S = pd.concat([df[[u]], score], axis=1)   # 得分矩阵（行=高校，列=学科）
```

现在我们需要从得分矩阵中提取出 East China Normal University 的得分向量：

```python
mask = S[u].str.contains(TARGET, case=False, na=False) | S[u].str.contains("华东师范", na=False)
if not mask.any():
    raise SystemExit(f"target not found: {TARGET}")
t = S.loc[mask, subs].iloc[0].to_numpy(float)
```

我们使用余弦相似度来衡量两所高校在各个学科得分上的相似程度：

```python
M = S.loc[~mask, subs].to_numpy(float)  # 取其他高校的得分矩阵
names = S.loc[~mask, u].to_numpy()     # 取其他高校名称

denom = np.linalg.norm(M, axis=1) * np.linalg.norm(t)  # 计算分母：向量的模
sims = (M @ t) / denom  # 计算余弦相似度
ok = np.isfinite(sims)  # 处理无效值
names, sims = names[ok], sims[ok]  # 过滤无效的相似度
```

最后，我们将计算出的相似度按照降序排序，并输出到文件：

```python
order = np.argsort(-sims)  # 按相似度从高到低排序
with open(OUT, "w", encoding="utf-8") as f:
    f.write(f"Similar to EAST CHINA NORMAL UNIVERSITY (N={len(order)})\n")
    for i, idx in enumerate(order, 1):
        f.write(f"{i:4d}. {names[idx]} | sim={sims[idx]:.4f}\n")
```

完整代码在附件中，叫 8_ecnu_similar.py

运行代码后，所有高校按照与华师大的**相似度从高到低**，都打印出来了，完整结果见 8_ecnu_similar.txt

可见，滑铁卢大学、北京师范大学、电子科技大学与华师大最相似

![](.\pictures\10.png)

#### 9. 请通过探索性分析的方式，对华东师范大学做一个学科画像?用尽可能多的角度去做。

承接上次作业的第五题：通过写SQL语句，获取华东师范大学在各个学科中的排名

第五题的结果文件（命名为 9_ecnu_data.csv），刚好可以作为本题的数据来源：

![](.\pictures\11.png)

上课的时候，胡老师提到了探索性分析：

​	如果数据不够直观，我们可以通过**画图**来更直观地看到数据的分布和变化

我选择了柱状图、饼图、雷达图

先聚焦于**被引用次数**，制作一个**雷达图**：

![](.\pictures\12.png)

学科画像（1）：

1. 化学学科的被引用次数非常突出，这是华东师范大学最强的学科之一，排名靠前且引用次数显著高于其他学科，说明化学领域的研究成果在国际上有较高的影响力。
2. 临床医学尽管排名较后，但引用次数较高，表明该领域有较强的学术产出和影响力。
3. 分子生物学和药理学，这两个学科的引用次数也较为突出，表明该校在生命科学和医学研究方面有一定的优势。
4. 农业科学虽然排名较高，但是其被引用次数较低，说明该领域的影响力相对较弱。
5. 心理学虽然排名在前列，但是在引用次数上的表现较为一般，表明该学科的学术影响力还有提升空间。
6. **学科多样性**：华东师范大学的学科覆盖范围广泛，涵盖了自然科学（化学、物理、地学等）、生命科学（生物学、医学等）以及社会科学（社会学、心理学等）。通过雷达图可以看出，虽然在一些领域（如生物学、地学、社会学）排名处于中等，但大部分学科的影响力在逐步上升。
7. 排名与引用次数的关系：排名与引用次数之间并不总是成正比，前面的几条可以作为很好的例子
8. 科研影响力的广泛性：华东师范大学在一些热门学科（如化学、分子生物学等）有着显著的科研成果和较高的国际影响力，这表明该校的科研工作具有较强的国际竞争力，尤其在自然科学领域。

再针对文献数量做一个饼图：

![](.\pictures\13.png)

学科画像（2）：

1. 化学学科文献数量突出，5420篇 占据了较大的比例，显示出华东师范大学在化学领域有着强大的研究产出和广泛的学术影响力。这表明该学科在国际和国内的学术界具有重要的地位，且该校在该学科的研究投入与成果持续增长。

2. 生物学和分子生物学的学术影响力较强，文献数量较多，分别为 897 和 532。这表明华东师范大学在生命科学和生物医学领域的研究较为活跃，且取得了显著成果。

3. 社会科学领域文献较为均衡，达到了 2176篇，表明该学科在学术界有一定的影响力，但相较于自然科学领域，数量上有所不足。这可能表明社会科学领域仍有较大的发展潜力。

4. 较弱的学科：农业科学和药理学与毒理学的文献数量较少（分别为 346 和 289），这可能表明这些学科的学术产出相对较低，或是研究的重点尚未达到更广泛的国际认可。

5. 学科多样性：华东师范大学的学科涵盖了自然科学、生命科学和社会科学，从文献分布来看，虽然自然科学（如化学、物理、地学）占据了文献的较大比例，但生命科学和社会科学的学术贡献也不可忽视，体现了学校多学科交叉的特点。

6. 学科发展潜力：从文献数量的分布来看，化学和生物学的领先地位仍然保持，而社会科学和医学等学科的逐步提升表明该校的学科发展潜力巨大，尤其在国际化和跨学科研究方面有较大的发展空间。

最后，把各学科排名做成一个柱状图：

![](.\pictures\14.png)

这个图有什么用？纵轴是很有意思的，它划分了不同排名区间，500为一组

学科画像（3）：

1. 首先，不难看出，华师大的世界前500学科是非常多的，形象来讲，前面一半以上的学科排名对应的柱子都很矮，低于500那条线

2. 500-1000 名的学科也有几个，只有最后一个是2500+的

3. **学科多样性**：华东师范大学的学科涵盖了从**自然科学**（如化学、物理、生命科学）到**社会科学**（如社会学、心理学）等多个领域。大部分学科排名集中在500名内，表现平稳，这显示出学校的学科发展较为均衡，特别是在自然科学领域。

4. 排名较高的学科（例如化学、计算机科学）显示出华东师范大学的科研优势，而排名较低的学科（如农业科学）可能需要更多的资源和投入来提升其国际影响力。

5. **排名与学术产出之间的关系**：从图表的分布来看，排名较高的学科（如化学、计算机科学）通常也伴随着较高的学术产出（文献和引用次数），而排名较低的学科（如农业科学、药理学）则在学术产出上显得较弱，显示出排名与科研影响力之间的一定关联。

最终，我们融合一下三次探索性分析得到的三个华师大的学科画像：

1. **化学学科的科研优势**
   
   **化学**是华东师范大学最强的学科之一，排名在前（90）且文献数量（5420篇）和引用次数（164390）非常突出，表明化学领域的研究成果在国际上有较高的影响力。该学科在国际学术界占据重要地位，且该校在该学科的研究投入与成果持续增长。
   
2. **生命科学的学术影响力**
   
   **生物学与生物化学**和**分子生物学**的文献数量也较为突出，分别为 897 和 532，显示出华东师范大学在生命科学领域的研究较为活跃，并取得显著成果。尽管这些学科的排名不如化学，但它们依然在学术界具有一定的影响力。
   
3. **社会科学的潜力**
   
   **社会科学**文献数量为 2176篇，表现出该学科在学术界的影响力较为均衡，但相较于自然科学领域，数量上有所不足。这可能表明社会科学领域仍有较大的发展潜力。该学科在学术产出和国际影响力上仍有进一步提升的空间。
   
4. **学科的相对弱势**
   **农业科学**和**药理学与毒理学**的文献数量较少，分别为 346 和 289，显示出这些学科的学术产出相对较低，或是这些学科的研究重点尚未达到更广泛的国际认可。需要更多的资源和学术投入，以提升它们的科研影响力。

5. **学科多样性**
   华东师范大学的学科覆盖范围广泛，涵盖了自然科学（如化学、物理、生命科学等）、生命科学（如生物学、医学等）以及社会科学（如社会学、心理学等）。大部分学科排名集中在**500名以内**，表现平稳，显示出学校学科发展较为均衡，尤其在自然科学领域。

6. **排名与学术产出之间的关系**
   从图表的分布来看，排名较高的学科（如化学、计算机科学）通常也伴随着较高的学术产出（文献和引用次数），而排名较低的学科（如农业科学、药理学）则在学术产出上显得较弱，显示出排名与科研影响力之间的一定关联。

7. **科研影响力的广泛性**
   华东师范大学在一些热门学科（如化学、分子生物学等）有着显著的科研成果和较高的国际影响力，这表明该校的科研工作具有较强的国际竞争力，尤其在自然科学领域。

8. **学科发展潜力**
   
   从文献数量的分布来看，**化学**和**生物学**的领先地位仍然保持，而**社会科学**和**医学**等学科的逐步提升表明该校的学科发展潜力巨大，尤其在国际化和跨学科研究方面有较大的发展空间。


#### 10. 请利用数据建模的方式，对各学科做一个排名模型，能够较好的预测出排名位置。

#### (可以用各学科前60%的数据作为训练集，后20%的数据作为测试集)

数据分为三类：训练集、验证集、测试集

测试集在训练模型时，不能让模型知道，否则测试就没有意义了

首先，我们读取每个学科的表格，将输出都放到outputs文件夹中

```python
CLEAN_DIR = (Path(__file__).resolve().parent / "clean")
OUT_DIR = (Path(__file__).resolve().parent / "outputs")
RANDOM_STATE = 42
os.makedirs(OUT_DIR, exist_ok=True)
```

然后搭建脚本的主循环框架：

先用 glob 找到 clean 目录下的所有 CSV 文件并按文件名排序，然后按顺序逐个打开处理

对每个文件读取时用 try/except 包裹以防单个文件损坏或格式异常导致整个批处理终止

一旦成功读取，就打印学科名与数据的行列信息，作为处理的上下文说明

```python
csvs = sorted(glob.glob(os.path.join(CLEAN_DIR, "*.csv")))
if not csvs:
    print("未在 'clean' 目录找到任何 csv 文件。")
for f in csvs:
    try:
        df = pd.read_csv(f)
    except Exception as e:
        print(f"读取失败：{f}，跳过。错误：{e}")
        continue

    subject = os.path.splitext(os.path.basename(f))[0]
    print(f"\n处理学科：{subject}，行数={len(df)}，列数={len(df.columns)}")
```

我们可以直接把表格的第一列当作排名

机构名称优先取 Institutions 列，如果那列不存在则退回取第一个字符串类型的列

如果连字符串列都没有，则假定第二列是机构名并用它

```python
y = pd.to_numeric(df.iloc[:, 0], errors='coerce')  # 第一列为排名，强制转数值
# Institutions 列优先，否则第一个 object 列，否则退回第二列
if 'Institutions' in df.columns:
    names = df['Institutions'].astype(str)
else:
    obj_cols = [c for c in df.columns if df[c].dtype == object]
    names = df[obj_cols[0]].astype(str) if obj_cols else df.iloc[:, 1].astype(str)
```

把除排名和机构名以外的列当作特征 X

对于**非数值**列我们采用 pd.get_dummies 做 one-hot 编码

对于**数值**列则用中位数填补缺失值

最后，确保 X 的所有列都转换为浮点数以便后续模型可以直接接受

```python
drop_cols = [df.columns[0]]
if 'Institutions' in df.columns:
    drop_cols.append('Institutions')
X = df.drop(columns=drop_cols, errors='ignore').copy()

nonnum = X.select_dtypes(exclude=[np.number]).columns.tolist()
if nonnum:
    X = pd.get_dummies(X, columns=nonnum, dummy_na=True, drop_first=True)

for c in X.columns:
    if X[c].isna().any():
        col_med = X[c].median()
        X[c].fillna(col_med if not np.isnan(col_med) else 0, inplace=True)
  
X = X.astype(float)
```

如何划分数据？

首先把整体数据的 20% 随机切为测试集，剩下的 80% 再从中按 25% 切出验证集

这样得到最终的 60% 训练、20% 验证、20% 测试

```
# 6. split: first test 20%, then from remaining split 25% as val (-> total 60/20/20)
X_temp, X_test, y_temp, y_test, names_temp, names_test = train_test_split(
    X, y, names, test_size=0.2, random_state=RANDOM_STATE, shuffle=True
)
X_train, X_val, y_train, y_val, names_train, names_val = train_test_split(
    X_temp, y_temp, names_temp, test_size=0.25, random_state=RANDOM_STATE, shuffle=True
)
```

然后进行简单的验证调参，选择 best_depth

用验证集在两个 5 与 None 之间选择哪个能得到更低的验证集 MAE

```python
best_depth = None
best_mae = 1e9
for depth in (5, None):
    model = RandomForestRegressor(n_estimators=200, max_depth=depth, random_state=RANDOM_STATE, n_jobs=-1)
    model.fit(X_train, y_train)
    p = model.predict(X_val)
    m = mean_absolute_error(y_val, p)
    if m < best_mae:
        best_mae = m
        best_depth = depth
```

最后，我们把训练集和验证集合并以训练最终模型

训练时我们把树的数量 n_estimators 设为 300 以取得更平滑的预测

然后在测试集上得到原始浮点预测值 pred_raw 并同时把它四舍五入为整数 pred_round

计算测试集上的 MAE 并把 Institutions、真实排名、四舍五入预测排名与原始预测分数保存为一个 CSV 文件

最后在屏幕上打印测试集的一部分表格和 MAE 值，以便实时观察情况

```python
X_comb = pd.concat([X_train, X_val], ignore_index=True)
y_comb = pd.concat([y_train, y_val], ignore_index=True)
final = RandomForestRegressor(n_estimators=300, max_depth=best_depth, random_state=RANDOM_STATE, n_jobs=-1)
final.fit(X_comb, y_comb)

pred_raw = final.predict(X_test)
pred_round = np.rint(pred_raw).astype(int)
mae = mean_absolute_error(y_test, pred_raw)

out = pd.DataFrame({
    'Institutions': names_test,
    'true_rank': y_test.values,
    'pred_rank': pred_round,
    'pred_rank_raw': pred_raw
})
out = out.sort_values('true_rank').reset_index(drop=True)

out_path = os.path.join(OUT_DIR, f"{subject}_test_predictions.csv")
out.to_csv(out_path, index=False, encoding='utf-8-sig')
print(out[['Institutions', 'true_rank', 'pred_rank']])
print(f"MAE (test) = {mae:.4f}  -> 已保存: {out_path}")
```

完整代码见 10_machine_learning.py

测试结果保存到了outputs文件夹中

我还打印了一份总表，对于每个学科，给出样本数量和测试集上的平均绝对误差

![](.\pictures\15.png)
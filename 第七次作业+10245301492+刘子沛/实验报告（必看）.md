## 实验七：深度学习算法升级

#### 1. 作业要求

上次作业中，我利用了深度学习方法，对各学科做一个排名模型，能够较好的预测出排名位置，并且利用MSE，MAPE等指标来进行评价模型的优劣

本次作业中，我需要升级这个模型

#### 2. 上次作业回顾

原数据的第一行和最后一行有冗余信息，可能会干扰表格的读取

第一行是表头，应该去掉：

![](.\pictures\1.png)

最后一行是 Copyright ?2025 Clarivate，也应该去掉：

![](.\pictures\3.png)

在 Powershell 执行下面命令：

```powershell
$src="D:\ESI\download"; $dst="D:\ESI\clean"; New-Item -ItemType Directory -Force -Path $dst | Out-Null
Get-ChildItem $src -Filter *.csv | ForEach-Object {
 $lines = Get-Content $_.FullNameGet-ChildItem $src -Filter *.csv
 $lines[1..($lines.Count-2)] | Set-Content -Encoding UTF8 (Join-Path $dst $_.Name)
}
```

解释一下：

1. src 是原始文件路径，dst 是目标文件路径
2. New-Item 用于创建一个新目录，如果 D:\ESI\clean 不存在，会自动创建
3. Get-ChildItem $src -Filter *.csv 会列出 src 中所有扩展名为 .csv 的文件
4. ForEach-Object 遍历每个文件
5. \$lines = Get-Content $_.FullName 会把整个文件的内容读成一个字符串数组，每一行是一个元素
6. \$lines[1..($lines.Count-2)] 是数组切片语法，表示从第二行到倒数第二行，删除文件的第一行和最后一行
7. Set-Content 把上一步得到的“去掉第一行的内容”写入到新的文件中

可以看到，第一行已经成功去掉了：

![](.\pictures\2.png)

最后一行也成功去掉了：

![](.\pictures\4.png)

我整理了一下邱学长提到的深度学习步骤：

> 定义数据集
> 定义模型
> 定义训练过程
> 训练多少轮次
> 参数冻结
> 在测试集上跑一遍
> 深层次MMP，每层加一些归一化、正则化、非线性组合

首先，题目要求我们对各学科做一个排名模型，预测排名位置

电脑通过学习一些国家的（Web of Science Documents，Cites，Cites/Paper，Cites/Paper，排名），

再给其他国家的（Web of Science Documents，Cites，Cites/Paper，Cites/Paper），可以推测出排名

我们来明确一下输入和输出：

输入：多个 CSV，每个 CSV 代表一个学科，第一列就是排名，这是通过人工观察发现的

输出：对于每个学科，在**测试值**上跑预测模型，得出的**真实值**对比**预测值**的表，以及各项指标的总表

我们要明确一点，每个学科的排名预测模型都应该是**独立**的

因此，要循环遍历每个csv文件，**写一个循环**

在循环中，依次遍历存放多个 CSV 文件路径的列表，并同时获取每个文件的编号（从 1 开始）和路径

```python
for i, csv_path in enumerate(csvs, 1):
```
然后，取出当前表格最左侧的第一列列名，并打印当前处理进度，包括文件编号、总文件数、学科文件名以及该排名列的列名，用来提示程序正在处理哪个学科的排名数据

```python
label_col = df.columns[0]
print(f"\n=== [{i}/{len(csvs)}] 学科: {csv_path.name} | 排名列: {label_col} ===")
```

前面提到过了，我们通过一个学校的：

    X =（Web of Science Documents，Cites，Cites/Paper，Cites/Paper）

来预测它的排名，设为 Y

将表格中最左侧的排名列转成数值型，然后把剩下的所有列作为特征矩阵 X，并通过 to_numeric_df() 函数将这些特征列全部转换为数值类型，以便后续模型训练或聚类分析使用

```python
y_raw = pd.to_numeric(df[label_col], errors="coerce").astype(float)
X = df.drop(columns=[label_col])
X = to_numeric_df(X)
```

不要忘了过滤掉在排名列中存在缺失值的行，只保留排名有效的样本，使得 X 和 Y 严格对应且都是完整的数值型数据，从而确保后续训练或聚类过程不会受到缺失数据干扰

```python
mask = y_raw.notna()
X = X.loc[mask].copy()
y_raw = y_raw.loc[mask].astype(float)
```
然后，划分数据集

课堂上，老师讲解了测试集、验证集、测试集

邱学长也提到了合适的比例：60%，20%，20%

我们还要计算当前样本总数 N，并生成一个从 0 到 N-1 的索引数组 idx_all，然后调用 split_60_20_20_idx() 函数，基于给定随机种子 SEED 进行数据集的划分

```python
N = len(row_ids)
idx_all = np.arange(N)
idx_tr, idx_va, idx_te = split_60_20_20_idx(idx_all, seed=SEED)
```
然后，我们要 scale 一下特征，因为特征的大小范围很不统一

创建一个标准化器 StandardScaler()，以训练集数据为基准进行特征标准化处理——即让每个特征的均值为 0、标准差为 1

```python
scaler = StandardScaler()
X_train = scaler.fit_transform(X_np[idx_tr])
X_val   = scaler.transform(X_np[idx_va])
X_test  = scaler.transform(X_np[idx_te])
```

排名也要 scale 一下

经过下面的处理后，模型预测输出也是 [0,1] 之间的小数，更易收敛、数值稳定，并可在评估阶段反归一化回真实排名

```python
y_min = float(np.min(y_np))
y_max_v = float(np.max(y_np))
y_max = y_max_v if y_max_v != y_min else (y_min + 1.0)
def norm(y): return (y - y_min) / (y_max - y_min)

y_train = norm(y_np[idx_tr])
y_val   = norm(y_np[idx_va])
y_test  = norm(y_np[idx_te])
```
然后，调用自定义函数 train_one() 来训练一个深度学习模型，并返回在测试集上的预测结果

```python
_, predict_rank = train_one(
   X_train, y_train, X_val, y_val, X_test, y_test,
   y_min=y_min, y_max=y_max, device=device
)
```
先插叙一下，深度学习模型的**内部**是怎么工作的？

首先，动态选择合适的归一化方式，构建深度学习模型，并定义一个稳健的损失函数

```python
norm_kind = "batch" if len(X_train) >= 2 else "layer"
model = DeepRankMLP(X_train.shape[1], norm_kind=norm_kind).to(device)
huber = nn.SmoothL1Loss(beta=1.0)  # robust to outliers
```

训练分为两个阶段，full training 和 freeze and fine-tune

**1. full training**

先用 AdamW 优化器，并配上 StepLR 学习率调度器（每 40 个 epoch 将学习率乘以 0.5），随后把训练集与验证集的 NumPy 特征/标签  转成 PyTorch 张量 并封装为 TensorDataset，为后续用 DataLoader 批量迭代训练与评估做准备

```python
opt = torch.optim.AdamW(model.parameters(), lr=LR1, weight_decay=WEIGHT_DECAY) sched = torch.optim.lr_scheduler.StepLR(opt, step_size=40, gamma=0.5) tr_ds = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train_norm).float()) va_ds = TensorDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val_norm).float())
```
构建 PyTorch 的 DataLoader，也就是让模型能够按批次取出训练数据和验证数据的关键部分

```python
bs_eff = min(BATCH_SIZE, len(tr_ds))
drop_last = (len(tr_ds) >= 2)
tr_dl = DataLoader(tr_ds, batch_size=bs_eff, shuffle=True, drop_last=drop_last)
va_dl = DataLoader(va_ds, batch_size=min(BATCH_SIZE, len(va_ds)), shuffle=False)
```

把模型输出的归一化预测结果（0~1之间）反变换回原始排名范围

因为我们前面把排名 scale 到了 0~1之间，可是题目想要的肯定是预测原始排名

```python
def denorm(y_hat_norm: np.ndarray) -> np.ndarray:
   return y_min + np.clip(y_hat_norm, 0.0, 1.0) * (y_max - y_min)
```

下面实现一个完整的训练轮次循环

每轮训练都会遍历整个训练集，将模型设为训练模式，再逐批取出数据送入网络进行前向传播，计算预测值与真实值的 Huber 损失

接着清空梯度、反向传播、裁剪梯度防止爆炸，最后用 AdamW 优化器更新参数

每个 epoch 结束后，学习率调度器按计划降低学习率，以帮助模型在后期更平稳地收敛

```python
nonlocal best_state, best_val_mse_rank
for ep in range(1, epochs + 1):
   if len(tr_dl) == 0:
       break
   model.train()
   for xb, yb in tr_dl:
       xb, yb = xb.to(device), yb.to(device)
       pred = model(xb)
       loss = huber(pred, yb)
       opt.zero_grad()
       loss.backward()
       nn.utils.clip_grad_norm_(model.parameters(), 5.0)
       opt.step()
   sched.step()
```

先切换到 eval 模式并关闭梯度计算，然后用验证集逐批预测，得到所有预测值和真实值

接着将它们反归一化为原始排名，用 MSE 计算误差

若当前误差小于历史最优值，就更新 best_val_mse_rank 并保存当前模型参数

```python
model.eval()
with torch.no_grad():
   yp, yt = [], []
   for xb, yb in va_dl:
       xb = xb.to(device)
       yp.append(model(xb).cpu().numpy())
       yt.append(yb.cpu().numpy())
   if len(yp) == 0:
       continue
   y_pred_norm = np.concatenate(yp).reshape(-1)
   y_true_norm = np.concatenate(yt).reshape(-1)
   y_pred_rank = denorm(y_pred_norm)
   y_true_rank = denorm(y_true_norm)
   v_mse_rank = mse_np(y_true_rank, y_pred_rank)
   if v_mse_rank < best_val_mse_rank:
       best_val_mse_rank = v_mse_rank
       best_state = {k: v.clone() for k, v in model.state_dict().items()}
```
**2. freeze and fine-tune**

接下来是第二部分，冻结参数训练

首先调用冻结模型前半部分的参数，只让后半部分参与训练

接着，用 AdamW 优化器重新初始化，只更新未冻结部分的参数，并设置一个更小的学习率 LR2 与相同的 weight_decay 来避免过拟合

然后建立新的 StepLR 调度器，每 20 轮将学习率减半

最后调用 run_epochs(EPOCHS_2) 进行多轮训练

```python
freeze_first_half(model, True)
opt = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR2, weight_decay=WEIGHT_DECAY)
sched = torch.optim.lr_scheduler.StepLR(opt, step_size=20, gamma=0.5)
run_epochs(EPOCHS_2)
```

最后是预测排名阶段

首先，将模型切换到评估模式，关闭 dropout 和 batch norm 的随机行为

关闭梯度计算，避免浪费显存和计算资源

把输入的 NumPy 数组 X_np 转换为 PyTorch 张量并移动到设备上

调用模型获得预测的归一化输出 yhat_norm，再转回 NumPy 格式

通过 denorm() 函数反归一化，将结果映射回真实的排名区间

```python
def predict_rank(X_np: np.ndarray) -> np.ndarray:
   model.eval()
   with torch.no_grad():
       X_t = torch.from_numpy(X_np).float().to(device)
       yhat_norm = model(X_t).cpu().numpy().reshape(-1)
   return denorm(yhat_norm)
```

最后，利用训练好的模型在测试集上进行预测，并计算预测结果与真实排名之间的多种评估指标，用于衡量模型性能

```python
y_pred_te = predict_rank(X_test)
y_true_te = y_np[idx_te]

metrics = compute_metrics(y_true_te, y_pred_te)
```

关于输出部分，我们前面提到过了：

对于每个学科，在**测试值**上跑预测模型，得出的**真实值**对比**预测值**的表，以及各项指标的总表

首先是各项指标的输出，需要的数据都在metrics字典中

依次输出即可

```python
print("[测试] " + "  ".join([
   f"MSE={metrics['MSE']:.4f}",
   f"RMSE={metrics['RMSE']:.2f}",
   f"MAE={metrics['MAE']:.2f}",
   f"MAPE={metrics['MAPE']:.2f}%",
   f"MedAE={metrics['MedianAE']:.2f}",
   f"R2={metrics['R2']:.3f}",
   f"nRMSE={metrics['nRMSE']:.3f}",
   f"Spearman={metrics['Spearman']:.3f}",
   f"Kendall={metrics['Kendall']:.3f}",
]))
```
然后是对比表

把模型在测试集上某所大学的真实排名和预测排名保存为一个独立的结果表

```python
pred_df = pd.DataFrame({
   "row_id": row_ids[idx_te],
   "true_rank": y_true_te,
   "pred_rank": y_pred_te,
})
```
生成每个学科预测结果的 CSV 文件名并保存预测结果表格

```python
stem = csv_path.stem
safe = "".join([ch if ch.isalnum() or ch in ("-","_") else "_" for ch in stem])
pred_path = (Path(__file__).resolve().parent / f"predictions_{safe}.csv")
pred_df.to_csv(pred_path, index=False)
print(f"已保存测试对比表: {pred_path.resolve()}")
```

但是我想把所有学科的各项指标汇总到一张表中，以便**纵向对比**

把每个学科对应的模型评估指标保存到一个总表列表中，以便最后统一生成总表

```python
row = {"subject_csv": csv_path.name}
row.update(metrics)
rows.append(row)
```
最后，在所有学科模型的预测模型评测结果汇总后，生成一个综合评价表 deep_learning.csv，并按 MSE 升序排序显示和保存


```python
if rows:
   out = pd.DataFrame(rows).sort_values("MSE")
   out_path = (Path(__file__).resolve().parent / "deep_learning.csv")
   out.to_csv(out_path, index=False)
   print("\n=== 总结（按 MSE 升序） ===")
   print(out.to_string(index=False))
   print(f"\n结果已保存到: {out_path.resolve()}")
```

以上的完整代码，请查看 deep_learning.py

各学科排名模型在**测试集**上的预测值与真实值对比表格，都在附件中：

![](.\pictures\6.png)

我这里随机选一个学科展示一下：

![](.\pictures\7.png)

可以看到，预测值与真实值还是比较接近的，说明模型预测效果好

预测的排名值是一个小数，而不是整数，虽然排名只能是整数

如果需要整数，把预测的排名值四舍五入即可，或者向偶数取整

不过我觉得小数也是有意义的，因为它本身只是一个估计

比如一个大学预测排名为 2.5，那可以认为它的排名大概是第二、第三

各学科排名模型在**测试集**上的**各项指标**如下：

![](.\pictures\5.png)

其中的 nRMSE 是 RMSE 按数值范围归一化之后的，很有参考价值：

​	nRMSE < 0.10：很好

​	0.10–0.20：可用

而各学科排名模型在**测试集**上的 nRMSE 都小于 0.10，说明模型预测效果**很好**

各项指标的总表也在附件中，叫 deep_learning.csv

#### 3. 升级上次的模型

##### （0）宏观思路

上次作业中，我已经采用了老师课堂强调的主流算法，因此本次以小步快跑的思路做稳健微调，不追求大改结构，重点围绕可复现、数值稳定与推理期后处理三条线优化，包括统一播种、早停与学习率调度、验证集线性标定、预测范围裁剪与整数化输出，同时控制计算预算，保证效果提升而训练时长基本不变

下面分块进行代码讲解，完整代码见 deep_learning_upgrade.py

##### （1）导入 os 与 random

在导入区补充 os 与 random，为后续统一管理随机性和轻量环境控制预留入口。它不改变任何训练与推理逻辑，只提供可复现实验所需的最小工程支点，避免因平台差异或默认随机源导致结果漂移。

```python
import os, random
```

##### （2）统一播种与数值稳定

新增播种函数一次性设置 random numpy torch 的种子，并在可用时开启卷积基准与高精度矩阵乘法，全程用异常保护保证兼容。这样数据划分权重初始化和丢弃层掩码可复现，训练曲线与评估更稳定。

```python
def _seed_all(seed: int = 42):
    try:
        random.seed(seed)
    except Exception:
        pass
    try:
        np.random.seed(seed)
    except Exception:
        pass
    try:
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)
        try:
            torch.backends.cudnn.benchmark = True
        except Exception:
            pass
        try:
            torch.set_float32_matmul_precision("high")
        except Exception:
            pass
    except Exception:
        pass
```

##### （3）轻量测试时丢弃平均

在推理阶段进行少量次前向，临时启用 Dropout 取多份独立输出后求均值，几乎不增加时间成本。该做法可抑制单次前向的方差与偶然抖动，常带来小而稳定的误差下降，不影响训练权重。

```python
def predict_rank_tta(X_np: np.ndarray, n_pass: int = 5) -> np.ndarray:
    outs = []
    with torch.no_grad():
        X_t = torch.from_numpy(X_np).float().to(device)
        for _ in range(max(1, n_pass)):
            model.train()  # enable dropout
            outs.append(model(X_t).cpu().numpy().reshape(-1))
        model.eval()
    yhat_norm = np.mean(np.vstack(outs), axis=0)
    return denorm(yhat_norm)
```

##### （4）主入口立即播种

在 main 开头读取固定种子并立刻播种，把所有随机过程纳入同一初始状态。它不修改全局变量，不使用关键字声明，避免作用域陷阱。由此数据划分标准化顺序和初始化轨迹都保持一致，评估可比。

```python
base_seed = SEED
_seed_all(base_seed)
```

##### （5）验证集线性标定

用验证集的预测与真实值拟合一元线性映射并设定合理边界，将该修正应用到测试预测。该步骤以极低成本消除整体偏移与缩放误差，常同时改善均方误差与绝对误差，不改变模型结构与训练。

```python
try:
    y_pred_va = predict_rank(X_va_s)
    y_true_va = y_va * (y_max - y_min) + y_min
    if len(y_pred_va) == len(y_true_va) and len(y_true_va) >= 5:
        a, b = np.polyfit(y_pred_va, y_true_va, 1)
        if np.isfinite(a) and np.isfinite(b):
            a = float(np.clip(a, 0.5, 2.0))
            b = float(np.clip(b, -2.0 * abs(np.mean(y_true_va)), 2.0 * abs(np.mean(y_true_va))))
            y_pred_te = a * y_pred_te + b
except Exception:
    pass
```

##### （6）范围裁剪稳住输出

将预测值限制在训练标签的最小最大区间内，切断极端外推带来的离群点。它对区间内多数样本无影响，却能显著降低重尾样本对指标的破坏，提升稳健性，且为纯向量化操作几乎零开销。

```python
try:
    y_pred_te = np.clip(y_pred_te, y_min, y_max)
except Exception:
    pass

y_true_te = y_np[idx_te]
```

##### （7）优雅地将预测值保存为整数

先检测真实标签是否近似整数，若成立再对预测做四舍五入。该策略与排名等级类评价的刻度一致，常显著降低绝对误差与均方误差；若标签为连续值则不会触发，避免对连续任务造成干扰。

```python
try:
    if np.allclose(y_true_te, np.round(y_true_te)):
        y_pred_te = np.round(y_pred_te)
except Exception:
    pass
```

##### （8）批量大小自适应防报错

在训练 DataLoader 处自适应调整批量，保证每批至少两条样本，若最后仅剩一条则丢弃该批。该改动专门化解批归一化对单样本批次的限制，避免报错又不改变总体样本分布，对大数据集无感知。

```python
try:
    _eff_bs = max(2, min(BATCH_SIZE, len(tr_dl.dataset)))
    _drop_last = (len(tr_dl.dataset) % _eff_bs == 1)
    tr_dl = DataLoader(tr_dl.dataset, batch_size=_eff_bs, shuffle=True, drop_last=_drop_last)
except Exception:
    pass
```

#### 4. 优化效果展示

运行升级后的代码

各学科排名模型在**测试集**上的预测值与真实值对比表格，都在附件中：

![](.\pictures\12.png)

我这里随机选一个学科展示一下

和上次不同的是，本次的预测值优雅地保存为了**整数**：

![](.\pictures\13.png)

各学科排名模型在**测试集**上的**各项指标**如下：

![](.\pictures\14.png)

其中的 nRMSE 是 RMSE 按数值范围归一化之后的，很有参考价值：

​	nRMSE < 0.10：很好

​	0.10–0.20：可用

而各学科排名模型在**测试集**上的 nRMSE 都小于 0.10，说明模型预测效果**很好**

各项指标的总表也在附件中，叫 deep_learning.csv 

升级后，**nRMSE** 大部分在 0.01 到 0.02，预测效果有了**显著提升**